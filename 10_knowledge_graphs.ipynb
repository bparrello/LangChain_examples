{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IJvl-EEESCA"
      },
      "source": [
        "# <font color=red>LangChain:  Knowledge Graph Support\n",
        "- https://docs.langchain.com/docs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<span style=\"font-family:'Comic Sans MS', cursive, sans-serif;\"><font color=orange>\n",
        "## Demo 1 - Simple Knowledge Graph created from text </br>And Used for Inference\n",
        "</font></span>\n",
        "This program creates a knowledge graph from text using:  </br>\n",
        "    &nbsp;&nbsp;&nbsp;&nbsp;\n",
        "    <font color=lightgreen>graph = index_creator.from_text(text)</font></br>\n",
        "Note that part of the program is inside an \"if False:\" which you may want to change to True in order to plot the graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.indexes import GraphIndexCreator\n",
        "from langchain.chains import GraphQAChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "llm = ChatOpenAI(model_name='gpt-4', temperature=0, max_tokens=256)\n",
        "\n",
        "text = \"Apple announced the Vision Pro in 2023.\"\n",
        "\n",
        "index_creator = GraphIndexCreator(llm=llm)\n",
        "graph = index_creator.from_text(text)\n",
        "print( graph.get_triples() )\n",
        "\n",
        "chain = GraphQAChain.from_llm(llm, graph=graph, verbose=True)\n",
        "question = \"When did apple announced the Vision Pro?\"\n",
        "response = chain.run(question)\n",
        "print(response)\n",
        "\n",
        "if False:   # change to True if you want to draw the graph ########\n",
        "    import networkx as nx\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    # create graph\n",
        "    G = nx.DiGraph()\n",
        "    G.add_edges_from((source, target, {'relation': relation}) for source, relation, target in graph.get_triples())\n",
        "\n",
        "    # plot the graph\n",
        "    plt.figure(figsize=(10,8), dpi=100)\n",
        "    pos = nx.spring_layout(G, k=3, seed=0)\n",
        "\n",
        "    nx.draw_networkx_nodes(G, pos, node_size=2000)\n",
        "    nx.draw_networkx_edges(G, pos, edge_color='gray')\n",
        "    nx.draw_networkx_labels(G, pos, font_size=12)\n",
        "    edge_labels = nx.get_edge_attributes(G, 'relation')\n",
        "    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=10)\n",
        "\n",
        "    # display the plot\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<span style=\"font-family:'Comic Sans MS', cursive, sans-serif;\"><font color=orange>\n",
        "## Demo 2 - Larger Knowledge Graph created from triples added individually</br>And Used for Inference\n",
        "</font></span>\n",
        "This program creates a knowledge graph from triples added individually using:  </br>\n",
        "    &nbsp;&nbsp;&nbsp;&nbsp;\n",
        "    <font color=lightgreen> graph.add_triple(KnowledgeTriple(node1, relation, node2))</font></br>\n",
        "Note that part of the program is inside an \"if False:\" which you may want to change to True in order to plot the graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.indexes import GraphIndexCreator\n",
        "from langchain.chains import GraphQAChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.graphs.networkx_graph import KnowledgeTriple\n",
        "\n",
        "# Knowledge graph\n",
        "kg = [\n",
        "    ('Apple', 'is', 'Company'),\n",
        "    ('Apple', 'created', 'iMac'),\n",
        "    ('Apple', 'created', 'iPhone'),\n",
        "    ('Apple', 'created', 'Apple Watch'),\n",
        "    ('Apple', 'created', 'Vision Pro'),\n",
        "\n",
        "    ('Apple', 'developed', 'macOS'),\n",
        "    ('Apple', 'developed', 'iOS'),\n",
        "    ('Apple', 'developed', 'watchOS'),\n",
        "\n",
        "    ('Apple', 'is located in', 'USA'),\n",
        "    ('Steve Jobs', 'co-founded', 'Apple'),\n",
        "    ('Steve Wozniak', 'co-founded', 'Apple'),\n",
        "    ('Tim Cook', 'is the CEO of', 'Apple'),\n",
        "\n",
        "    ('iOS', 'runs on', 'iPhone'),\n",
        "    ('macOS', 'runs on', 'iMac'),\n",
        "    ('watchOS', 'runs on', 'Apple Watch'),\n",
        "\n",
        "    ('Apple', 'was founded in', '1976'),\n",
        "    ('Apple', 'owns', 'App Store'),\n",
        "    ('App Store', 'sells', 'iOS apps'),\n",
        "\n",
        "    ('iPhone', 'announced in', '2007'),\n",
        "    ('iMac', 'announced in', '1998'),\n",
        "    ('Apple Watch', 'announced in', '2014'),\n",
        "    ('Vision Pro', 'announced in', '2023'),\n",
        "]\n",
        "\n",
        "llm = ChatOpenAI(model_name='gpt-4', temperature=0, max_tokens=256)\n",
        "\n",
        "index_creator = GraphIndexCreator(llm=llm)\n",
        "graph = index_creator.from_text('')\n",
        "for (node1, relation, node2) in kg:\n",
        "    graph.add_triple(KnowledgeTriple(node1, relation, node2))\n",
        "\n",
        "chain = GraphQAChain.from_llm(llm, graph=graph, verbose=True)\n",
        "question = \"When did apple announce the vision pro?\"\n",
        "print( chain.run(question) )\n",
        "question = \"Who is Tim Cook?\"\n",
        "print( chain.run(question) )\n",
        "\n",
        "#### useful extras\n",
        "\n",
        "graph.write_to_gml(\"graph.gml\")\n",
        "from langchain.indexes.graph import NetworkxEntityGraph\n",
        "loaded_graph = NetworkxEntityGraph.from_gml(\"graph.gml\")\n",
        "print(loaded_graph.get_triples())\n",
        "\n",
        "if False:   # change to True if you want to draw the graph ########\n",
        "    import networkx as nx\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    G = nx.DiGraph()\n",
        "    for node1, relation, node2 in kg:\n",
        "        G.add_edge(node1, node2, label=relation)\n",
        "\n",
        "    plt.figure(figsize=(10, 8), dpi=100)\n",
        "    pos = nx.spring_layout(G, k=10, iterations=500, seed=42)\n",
        "    nx.draw_networkx_nodes(G, pos, node_size=5000)\n",
        "    nx.draw_networkx_edges(G, pos, edge_color='gray', edgelist=G.edges(), width=2)\n",
        "    nx.draw_networkx_labels(G, pos, font_size=12)\n",
        "    edge_labels = nx.get_edge_attributes(G, 'label')\n",
        "    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=12)\n",
        "    plt.axis('off')\n",
        "    plt.show()   # comment this out if not interested"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<span style=\"font-family:'Comic Sans MS', cursive, sans-serif;\"><font color=orange>\n",
        "## Demo 3 - One More Small Knowledge Graph Used for Inference\n",
        "</font></span>\n",
        "Note that part of the program is inside an \"if False:\" which you may want to change to True in order to plot the graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.graphs.networkx_graph import KnowledgeTriple\n",
        "\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "llm = ChatOpenAI(model_name='gpt-4', temperature=0, max_tokens=256)\n",
        "\n",
        "# Knowledge graph\n",
        "kg = [\n",
        "    (\"Anne\", \"is\", \"cold\"),\n",
        "    (\"Anne\", \"is\", \"nice\"),\n",
        "    (\"Anne\", \"is\", \"white\"),\n",
        "    (\"Bob\", \"is\", \"nice\"),\n",
        "    (\"Bob\", \"is\", \"white\"),\n",
        "    (\"Charlie\", \"is\", \"green\"),\n",
        "    (\"Charlie\", \"is\", \"round\"),\n",
        "    (\"Charlie\", \"is\", \"white\"),\n",
        "    (\"Erin\", \"is\", \"big\"),\n",
        "    (\"Erin\", \"is\", \"cold\"),\n",
        "]\n",
        "\n",
        "index_creator = GraphIndexCreator(llm=llm)\n",
        "graph = index_creator.from_text('')\n",
        "for (node1, relation, node2) in kg:\n",
        "    graph.add_triple(KnowledgeTriple(node1, relation, node2))\n",
        "\n",
        "chain = GraphQAChain.from_llm(llm, graph=graph, verbose=True)\n",
        "question = \"Is erin cold?\"\n",
        "print( chain.run(question) )\n",
        "\n",
        "if False:   # change to True if you want to draw the graph ########\n",
        "    G = nx.DiGraph()\n",
        "    for node1, relation, node2 in kg:\n",
        "        G.add_edge(node1, node2, label=relation)\n",
        "    plt.figure(figsize=(10, 8), dpi=100)\n",
        "    pos = nx.spring_layout(G, k=1, iterations=500, seed=0)\n",
        "    nx.draw_networkx_nodes(G, pos, node_size=5000)\n",
        "    nx.draw_networkx_edges(G, pos, edge_color='gray', edgelist=G.edges(), width=2)\n",
        "    nx.draw_networkx_labels(G, pos, font_size=12)\n",
        "    edge_labels = nx.get_edge_attributes(G, 'label')\n",
        "    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=12)\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMZi6NDm9npKydMJRyJPAT2",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
